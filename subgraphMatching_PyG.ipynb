{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2aca983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "12.4\n"
     ]
    }
   ],
   "source": [
    "# Torch version\n",
    "!python -c \"import torch; print(torch.__version__)\"\n",
    "\n",
    "# Cuda version\n",
    "!python -c \"import torch; print(torch.version.cuda)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d13a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Torch\n",
    "# !pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d218025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyG (automatic)\n",
    "# !pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "# !pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0b55461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/graph_matching/lib/python3.10/site-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /home/ealvarez/miniconda3/envs/graph_matching/lib/python3.10/site-packages/libpyg.so: undefined symbol: _ZN5torch8autograd12VariableInfoC1ERKN2at6TensorE\n",
      "  import torch_geometric.typing\n",
      "/home/ealvarez/miniconda3/envs/graph_matching/lib/python3.10/site-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/ealvarez/miniconda3/envs/graph_matching/lib/python3.10/site-packages/torch_scatter/_scatter_cuda.so: undefined symbol: _ZN5torch8autograd12VariableInfoC1ERKN2at6TensorE\n",
      "  import torch_geometric.typing\n",
      "/home/ealvarez/miniconda3/envs/graph_matching/lib/python3.10/site-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /home/ealvarez/miniconda3/envs/graph_matching/lib/python3.10/site-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  import torch_geometric.typing\n",
      "/home/ealvarez/miniconda3/envs/graph_matching/lib/python3.10/site-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/ealvarez/miniconda3/envs/graph_matching/lib/python3.10/site-packages/torch_sparse/_spmm_cuda.so: undefined symbol: _ZN5torch8autograd12VariableInfoC1ERKN2at6TensorE\n",
      "  import torch_geometric.typing\n",
      "/home/ealvarez/miniconda3/envs/graph_matching/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from model_PyG import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8498cd7",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from torch_geometric.transforms import Compose\n",
    "from torch_geometric.utils import dense_to_sparse, negative_sampling\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa1633e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric\n",
    "print(torch_geometric.__version__)\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c437961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info(data):\n",
    "\tprint(\"Validate:\\t {}\".format(data.validate(raise_on_error=True)))\n",
    "\tprint(\"Num. nodes:\\t {}\".format(data.num_nodes))\n",
    "\tprint(\"Num. edges:\\t {}\".format(data.num_edges))\n",
    "\tprint(\"Num. features:\\t {}\".format(data.num_node_features))\n",
    "\tprint(\"Has isolated:\\t {}\".format(data.has_isolated_nodes()))\n",
    "\tprint(\"Has loops:\\t {}\".format(data.has_self_loops()))\n",
    "\tprint(\"Is directed:\\t {}\".format(data.is_directed()))\n",
    "\tprint(\"Is undirected:\\t {}\".format(data.is_undirected()))\n",
    "\tprint(\"{}\".format(data.edge_index))\n",
    "\tprint(\"{}\".format(data.x))\n",
    "\tprint(\"{}\".format(data.edge_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7bef90",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7573a5c2",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "dataset = \"mentos_05\" # \"vanessa_05\", \"mentos_05\", \"Douban Online_Offline\", \"ACM_DBLP\" # args.dataset\n",
    "encoder = \"GINE\" # Change GIN, GINE\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if (dataset == \"ACM_DBLP\"):\n",
    "\ttrain_set = [\"ACM\", \"DBLP\"]\n",
    "\tb = np.load(\"data/ACM-DBLP.npz\")\n",
    "\t# train_features[\"ACM\"] = [torch.from_numpy(b[\"x1\"]).float()]\n",
    "\t# train_features[\"DBLP\"] = [torch.from_numpy(b[\"x2\"]).float()]\n",
    "\ttest_pairs = b[\"test_pairs\"].astype(np.int32)\n",
    "\tNUM_HIDDEN_LAYERS = 12\n",
    "\tHIDDEN_DIM = [1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024]\n",
    "\t# input_dim = 17\n",
    "\toutput_feature_size = 128\n",
    "\tlr = 1e-4 # 1e-4\n",
    "\tepochs = 100\n",
    "elif (dataset == \"Douban Online_Offline\"):\n",
    "\ttrain_set = [\"Online\", \"Offline\"]\n",
    "\ta1, f1, a2, f2, test_pairs = load_douban()\n",
    "\t# f1 = f1.A\n",
    "\t# f2 = f2.A\n",
    "\ttest_pairs = torch.tensor(np.array(test_pairs, dtype=int)) - 1\n",
    "\ttest_pairs = test_pairs.numpy()\n",
    "\t# train_features[\"Online\"] = [torch.from_numpy(f1).float()]\n",
    "\t# train_features[\"Offline\"] = [torch.from_numpy(f2).float()]\n",
    "\tNUM_HIDDEN_LAYERS = 6\n",
    "\tHIDDEN_DIM = [512, 512, 512, 512, 512, 512, 512]\n",
    "\t# input_dim = 538\n",
    "\toutput_feature_size = 512\n",
    "\tlr = 0.0001\n",
    "\tepochs = 100\n",
    "elif (dataset == \"mentos_05\"):\n",
    "\ttrain_set = [\n",
    "\t\t# \"Orange_1\", \"Orange_2\",\n",
    "\t\t\"Red_1\", \"Red_2\",\n",
    "\t\t# \"Yellow_1\", \"Yellow_2\"\n",
    "\t]\n",
    "\tNUM_HIDDEN_LAYERS = 12\n",
    "\tHIDDEN_DIM = [1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024]\n",
    "\toutput_feature_size = 16\n",
    "\tlr = 0.0001\n",
    "\tepochs = 100\n",
    "elif (dataset == \"vanessa_05\"):\n",
    "\ttrain_set = [\n",
    "\t\t\"FrescoAmazonas_1\", \"FrescoAmazonas_2\",\n",
    "\t\t\"FrescoCusco_1\", \"FrescoCusco_2\",\n",
    "\t\t\"FrescoSanMartin_1\", \"FrescoSanMartin_2\",\n",
    "\t\t\"SecoAmazonas_1\", \"SecoAmazonas_2\",\n",
    "\t\t\"SecoCusco_1\", \"SecoCusco_2\",\n",
    "\t\t\"SecoSanMartin_1\", \"SecoSanMartin_2\"\n",
    "\t]\n",
    "\tNUM_HIDDEN_LAYERS = 12\n",
    "\tHIDDEN_DIM = [1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024]\n",
    "\toutput_feature_size = 128\n",
    "\tlr = 0.0001\n",
    "\tepochs = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5096cf",
   "metadata": {},
   "source": [
    "### Understand Data (PyG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c60a890",
   "metadata": {},
   "source": [
    "#### Data (PyG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7906fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([\n",
    "\t[0, 1],\n",
    "\t[1, 2],\n",
    "\t[2, 3]], dtype=torch.long)\n",
    "x = torch.tensor([[0, 1], [1, 2], [2, 3], [3, 4]], dtype=torch.float)\n",
    "edge_weight = torch.tensor([0.5, 1.0, 1.5], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index.t().contiguous(), edge_weight=edge_weight)\n",
    "\n",
    "info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365f6e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([\n",
    "\t[0, 1],\n",
    "\t[1, 2],\n",
    "\t[2, 3]], dtype=torch.long)\n",
    "x = torch.tensor([\n",
    "\t[0, 1],\n",
    "\t[1, 2],\n",
    "\t[2, 3],\n",
    "\t[3, 4]], dtype=torch.float)\n",
    "edge_weight = torch.tensor([0.5, 1.0, 1.5], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index.t().contiguous(), edge_weight=edge_weight)\n",
    "\n",
    "transform = Compose([\n",
    "\tT.NormalizeFeatures(),\n",
    "\tT.ToUndirected(),\n",
    "\tT.AddSelfLoops(fill_value=1.0),\n",
    "\tT.ToDevice(device)\n",
    "])\n",
    "\n",
    "data = transform(data)\n",
    "\n",
    "info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf89e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([\n",
    "\t[0, 1],\n",
    "\t[1, 0],\n",
    "\t[1, 2],\n",
    "\t[2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([\n",
    "\t[0, 1], \n",
    "\t[1, 2], \n",
    "\t[2, 3]], dtype=torch.float)\n",
    "edge_weight = torch.tensor([0.5, 0.5, 1.0, 1.0], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index.t().contiguous(), edge_weight=edge_weight)\n",
    "\n",
    "info(data)\n",
    "transform = Compose([\n",
    "\tT.NormalizeFeatures(),\n",
    "\tT.ToUndirected(reduce=\"mean\"),\n",
    "\tT.AddSelfLoops(fill_value=1.0),\n",
    "\tT.ToDevice(device)\n",
    "])\n",
    "\n",
    "data = transform(data)\n",
    "\n",
    "info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb1a6a8",
   "metadata": {},
   "source": [
    "#### Data ACM_DBLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dabd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da75547",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index1 = b[\"edge_index1\"]\n",
    "print(edge_index1.shape)\n",
    "edge_index1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a32ba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index2 = b[\"edge_index2\"]\n",
    "print(edge_index2.shape)\n",
    "edge_index2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57346480",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = b[\"x1\"]\n",
    "print(x1.shape)\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9b06d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = b[\"x2\"]\n",
    "print(x2.shape)\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ceba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b6df31",
   "metadata": {},
   "source": [
    "#### Data Douban Online_Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389167d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2b333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1, f1, a2, f2, test_pairs = load_douban()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ae9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(a1.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdfa3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(a2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95fccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(f1.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16056b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(f2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bec322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index1, edge_attr1 = dense_to_sparse(torch.from_numpy(a1.toarray()))\n",
    "print(edge_index1.shape)\n",
    "edge_index1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b93b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index2, edge_attr2 = dense_to_sparse(torch.from_numpy(a2.toarray()))\n",
    "print(edge_index2.shape)\n",
    "edge_index2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e377a82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.from_numpy(f1.toarray()).float()\n",
    "print(x1.shape)\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e503c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = torch.from_numpy(f2.toarray()).float()\n",
    "print(x2.shape)\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48395b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058f1ae5",
   "metadata": {},
   "source": [
    "### Create Data (PyG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edbf1b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "\t# T.NormalizeFeatures(),\n",
    "\tT.ToUndirected(reduce=\"mean\"),\n",
    "\tT.AddSelfLoops(fill_value=1.0),\n",
    "\tT.ToDevice(device)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88486bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/graph_matching/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate:\t True\n",
      "Num. nodes:\t 1777\n",
      "Num. edges:\t 2134343\n",
      "Num. features:\t 6\n",
      "Has isolated:\t False\n",
      "Has loops:\t True\n",
      "Is directed:\t False\n",
      "Is undirected:\t True\n",
      "tensor([[   0,    0,    0,  ..., 1774, 1775, 1776],\n",
      "        [   1,    2,    3,  ..., 1774, 1775, 1776]], device='cuda:0')\n",
      "tensor([[ 1.8872e+00, -2.1626e+00,  5.1084e+00,  1.6168e-02,  3.1650e-03,\n",
      "          1.0000e+00],\n",
      "        [ 2.0378e+00, -2.1454e+00,  3.2162e+00,  3.4163e-01,  1.0622e-01,\n",
      "          1.0000e+00],\n",
      "        [ 1.7636e+00, -2.1379e+00,  4.2597e+00,  2.8798e-01,  6.7605e-02,\n",
      "          1.0000e+00],\n",
      "        ...,\n",
      "        [ 1.9196e+00,  1.7690e+00,  4.4899e+00,  1.2438e-01,  2.7701e-02,\n",
      "          1.0000e+00],\n",
      "        [ 2.0216e+00,  1.7732e+00,  4.6991e+00,  6.2988e-02,  1.3404e-02,\n",
      "          1.0000e+00],\n",
      "        [ 2.3582e+00,  1.7774e+00,  3.5178e+00,  5.4619e-01,  1.5527e-01,\n",
      "          1.0000e+00]], device='cuda:0')\n",
      "tensor([[ 0.5332],\n",
      "        [-0.9682],\n",
      "        [-0.6354],\n",
      "        ...,\n",
      "        [ 1.0000],\n",
      "        [ 1.0000],\n",
      "        [ 1.0000]], device='cuda:0')\n",
      "Validate:\t True\n",
      "Num. nodes:\t 1772\n",
      "Num. edges:\t 2171236\n",
      "Num. features:\t 6\n",
      "Has isolated:\t False\n",
      "Has loops:\t True\n",
      "Is directed:\t False\n",
      "Is undirected:\t True\n",
      "tensor([[   0,    0,    0,  ..., 1769, 1770, 1771],\n",
      "        [   1,    2,    3,  ..., 1769, 1770, 1771]], device='cuda:0')\n",
      "tensor([[ 1.8872, -2.1681,  4.8881,  0.0357,  0.0073,  1.0000],\n",
      "        [ 1.6625, -2.1665,  5.2904,  0.3673,  0.0694,  1.0000],\n",
      "        [ 2.0378, -2.1509,  4.4780,  0.1601,  0.0357,  1.0000],\n",
      "        ...,\n",
      "        [ 2.3099,  1.6447,  4.6107,  0.0438,  0.0095,  1.0000],\n",
      "        [ 1.8263,  1.6954,  5.0807,  0.0815,  0.0160,  1.0000],\n",
      "        [ 2.0685,  1.7516,  5.1852,  0.0934,  0.0180,  1.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.8170],\n",
      "        [-0.7395],\n",
      "        [ 0.6687],\n",
      "        ...,\n",
      "        [ 1.0000],\n",
      "        [ 1.0000],\n",
      "        [ 1.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading training datasets\")\n",
    "\n",
    "train_loader = {}\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "if dataset == \"ACM_DBLP\":\n",
    "\tfor i, ts in enumerate(train_set):\n",
    "\t\tedge_index = torch.tensor(b[f\"edge_index{i+1}\"], dtype=torch.long)\n",
    "\t\tx = torch.tensor(b[f\"x{i+1}\"], dtype=torch.float)\n",
    "\t\t# x = torch.tensor(scaler.fit_transform(x.numpy())) # scaling\n",
    "\t\t\n",
    "\t\t\"\"\" if i==1:\n",
    "\t\t\tx = x[torch.randperm(x.size(0))] # permutations for test \"\"\"\n",
    "\n",
    "\t\tdata = Data(x=x, edge_index=edge_index)\n",
    "\t\tdata = transform(data)\n",
    "\t\ttrain_loader[ts] = data\n",
    "\t\tinfo(data)\n",
    "elif dataset == \"Douban Online_Offline\":\n",
    "\tedge_index1, _= dense_to_sparse(torch.from_numpy(a1.toarray()))\n",
    "\tx1 = torch.from_numpy(f1.toarray()).float()\n",
    "\tdata1 = Data(x=x1, edge_index=edge_index1)\n",
    "\tdata1 = transform(data1)\n",
    "\ttrain_loader[train_set[0]] = data1\n",
    "\tinfo(data1)\n",
    "\n",
    "\tedge_index2, _= dense_to_sparse(torch.from_numpy(a2.toarray()))\n",
    "\tx2 = torch.from_numpy(f2.toarray()).float()\n",
    "\tdata2 = Data(x=x2, edge_index=edge_index2)\n",
    "\tdata2 = transform(data2)\n",
    "\ttrain_loader[train_set[1]] = data2\n",
    "\tinfo(data2)\n",
    "elif dataset in [\"vanessa_05\", \"mentos_05\"]: # Change\n",
    "\tfor ts in train_set:\n",
    "\t\tdf_edges = pd.read_csv(\"data/{}/edges_{}.csv\".format(dataset, ts))\n",
    "\t\t# source, target, weight, subgroup\n",
    "\t\tedge_index = torch.tensor(df_edges.iloc[:, [0, 1]].values, dtype=torch.long)\n",
    "\n",
    "\t\tedge_weight = torch.tensor(df_edges.iloc[:, 2].values, dtype=torch.float).view(-1, 1) # [E,1]\n",
    "\t\t\"\"\" edge_attr = torch.cat([\n",
    "\t\t\tedge_weight.abs(),         # strength\n",
    "\t\t\ttorch.sign(edge_weight),   # direction (+1, -1)\n",
    "\t\t\tedge_weight ** 2           # nonlinearity\n",
    "\t\t], dim=1) # [E,3] \"\"\"\n",
    "\n",
    "\t\tdf_nodes = pd.read_csv(\"data/{}/nodes_{}.csv\".format(dataset, ts))\n",
    "\t\t# idx, id, mz, rt, intensity_mean, intensity_std, intensity_cv, presence_ratio, 0, 1, 2, ...\n",
    "\t\tx = torch.tensor(df_nodes.iloc[:, [2, 3, 4, 5, 6, 7]].values, dtype=torch.float) # Change\n",
    "\t\t# x = torch.tensor(scaler.fit_transform(x.numpy())) # scaling\n",
    "\n",
    "\t\tdata = Data(x=x, edge_index=edge_index.t().contiguous(), edge_weight=edge_weight)\n",
    "\t\tdata = transform(data)\n",
    "\t\ttrain_loader[ts] = data\n",
    "\t\tinfo(data)\n",
    "\n",
    "\t\ttest_pairs = None # No use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f05221ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Red_1': Data(x=[1777, 6], edge_index=[2, 2134343], edge_weight=[2134343, 1]),\n",
       " 'Red_2': Data(x=[1772, 6], edge_index=[2, 2171236], edge_weight=[2171236, 1])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bae142",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b19b1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_num_neg_samples(edge_index, num_nodes, ratio):\n",
    "\tE = edge_index.size(1)\n",
    "\tmax_neg = num_nodes * num_nodes - E\n",
    "\treturn min(int(ratio * E), max_neg)\n",
    "\n",
    "def neg_ratio_schedule(epoch, max_epoch):\n",
    "\tstart = 5.0\n",
    "\tend = 1.0\n",
    "\treturn start - (start - end) * (epoch / max_epoch)\n",
    "\n",
    "class EarlyStopping:\n",
    "\tdef __init__(self, patience=5, delta=0, warmup=5, verbose=False):\n",
    "\t\tself.patience = patience\n",
    "\t\tself.delta = delta\n",
    "\t\tself.warmup = warmup\n",
    "\t\tself.verbose = verbose\n",
    "\t\tself.best_loss = None\n",
    "\t\tself.no_improvement_count = 0\n",
    "\t\tself.stop_training = False\n",
    "\t\n",
    "\tdef check_early_stop(self, loss, epoch):\n",
    "\t\tif epoch >= self.warmup:\n",
    "\t\t\tif self.best_loss is None or loss < self.best_loss - self.delta:\n",
    "\t\t\t\tself.best_loss = loss\n",
    "\t\t\t\tself.no_improvement_count = 0\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.no_improvement_count += 1\n",
    "\t\t\t\tif self.no_improvement_count >= self.patience:\n",
    "\t\t\t\t\tself.stop_training = True\n",
    "\t\t\t\t\tif self.verbose:\n",
    "\t\t\t\t\t\tprint(\"Stopping early as no improvement has been observed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dbeb1ba",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "def fit_TGAE_subgraph(encoder, dataset, no_samples, model, epochs, train_loader, lr, test_pairs=None):\n",
    "\tbest_hitAtOne = 0\n",
    "\tbest_hitAtFive = 0\n",
    "\tbest_hitAtTen = 0\n",
    "\tbest_hitAtFifty = 0\n",
    "\tlist_loss = []\n",
    "\n",
    "\toptimizer = Adam(model.parameters(), lr=lr,weight_decay=5e-4)\n",
    "\t\n",
    "\t# Initialize early stopping\n",
    "\tpatience = 10\n",
    "\tdelta = 1e-3 # 1e-4\n",
    "\twarmup = 10\n",
    "\tearly_stopping = EarlyStopping(patience=patience, delta=delta, warmup=warmup, verbose=True)\n",
    "\n",
    "\tloop_obj = tqdm(range(1, epochs + 1))\n",
    "\tfor epoch in loop_obj:\n",
    "\t\tloop_obj.set_description(f\"Epoch: {epoch}\")\n",
    "\t\t\n",
    "\t\t# Train\n",
    "\t\tmodel.train()\n",
    "\t\tloss = 0.0\n",
    "\t\t\n",
    "\t\tfor ts in random.sample(train_set, k=len(train_set)): # shuffle train_set\n",
    "\t\t\tdata = train_loader[ts]\n",
    "\t\t\t\n",
    "\t\t\t# Encoder\n",
    "\t\t\tif encoder == \"GIN\":\n",
    "\t\t\t\tz = model(data.x, data.edge_index)\n",
    "\t\t\t\t# z = F.normalize(z, dim=1)\n",
    "\t\t\telif encoder == \"GINE\":\n",
    "\t\t\t\tz = model(data.x, data.edge_index, data.edge_weight)\n",
    "\n",
    "\t\t\t# Positive edges\n",
    "\t\t\tpos_edge_index = data.edge_index\n",
    "\t\t\t\n",
    "\t\t\t# Negative edges\n",
    "\t\t\t# option 1\n",
    "\t\t\tneg_edge_index = negative_sampling(\n",
    "\t\t\t\tedge_index=data.edge_index,\n",
    "\t\t\t\tnum_nodes=z.size(0),\n",
    "\t\t\t\tnum_neg_samples=pos_edge_index.size(1), # Change 2 to other value if needed\n",
    "\t\t\t\tmethod=\"sparse\"\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\t# option 2 Negative edges (dynamic)\n",
    "\t\t\t\"\"\" ratio = neg_ratio_schedule(epoch, epochs)\n",
    "\t\t\tnum_neg = compute_num_neg_samples(\n",
    "\t\t\t\tedge_index=edge_index,\n",
    "\t\t\t\tnum_nodes=z.size(0),\n",
    "\t\t\t\tratio=ratio\n",
    "\t\t\t)\n",
    "\t\t\tneg_edge_index = negative_sampling(\n",
    "\t\t\t\tedge_index=edge_index,\n",
    "\t\t\t\tnum_nodes=z.size(0),\n",
    "\t\t\t\tnum_neg_samples=num_neg,\n",
    "\t\t\t\tmethod=\"sparse\"\n",
    "\t\t\t) \"\"\"\n",
    "\t\t\t\n",
    "\t\t\t# Decoder\n",
    "\t\t\t# option 1\n",
    "\t\t\tpos_logits = (z[pos_edge_index[0]] * z[pos_edge_index[1]]).sum(dim=1)\n",
    "\t\t\tneg_logits = (z[neg_edge_index[0]] * z[neg_edge_index[1]]).sum(dim=1)\n",
    "\t\t\t\n",
    "\t\t\t# option 2\n",
    "\t\t\t\"\"\" pos_logits = F.cosine_similarity(\n",
    "\t\t\t\tz[pos_edge_index[0]],\n",
    "\t\t\t\tz[pos_edge_index[1]],\n",
    "\t\t\t\tdim=1\n",
    "\t\t\t)\n",
    "\t\t\tneg_logits = F.cosine_similarity(\n",
    "\t\t\t\tz[neg_edge_index[0]],\n",
    "\t\t\t\tz[neg_edge_index[1]],\n",
    "\t\t\t\tdim=1\n",
    "\t\t\t) \"\"\"\n",
    "\n",
    "\t\t\t# Loss\n",
    "\t\t\tpos_labels = torch.ones_like(pos_logits)\n",
    "\t\t\tneg_labels = torch.zeros_like(neg_logits)\n",
    "\n",
    "\t\t\t# option 1\n",
    "\t\t\t\"\"\" loss_pos = binary_cross_entropy_with_logits(pos_logits, pos_labels)\n",
    "\t\t\tloss_neg = binary_cross_entropy_with_logits(neg_logits, neg_labels)\n",
    "\t\t\tloss += loss_pos + loss_neg \"\"\"\n",
    "\n",
    "\t\t\t# option 2\n",
    "\t\t\t# num_pos = pos_edge_index.size(1)\n",
    "\t\t\t# num_neg = neg_edge_index.size(1)\n",
    "\t\t\t# pos_weight = torch.tensor([num_neg / num_pos], device=device)\n",
    "\t\t\tlogits = torch.cat([pos_logits, neg_logits], dim=0)\n",
    "\t\t\tlabels = torch.cat([pos_labels, neg_labels], dim=0)\n",
    "\t\t\tloss_temp = F.binary_cross_entropy_with_logits(logits, labels) #, pos_weight=pos_weight) # with pos_weight\n",
    "\t\t\tloss += loss_temp\n",
    "\t\t\t\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss = loss / no_samples\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\tloop_obj.set_postfix_str(f\"Loss: {loss.item():.4f}\")\n",
    "\t\tlist_loss.append(loss.item())\n",
    "\n",
    "\t\t# Check early stopping condition\n",
    "\t\tearly_stopping.check_early_stop(loss.item(), epoch)\n",
    "\t\tif early_stopping.stop_training:\n",
    "\t\t\tprint(f\"Early stopping at epoch {epoch}\")\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\t# Evaluation (for firts dataset)\n",
    "\t\t\"\"\" model.eval()\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tkeys = list(train_loader.keys())\n",
    "\t\t\tdata1 = train_loader[keys[0]]\n",
    "\t\t\tdata2 = train_loader[keys[1]]\n",
    "\n",
    "\t\t\tz1 = model(data1.x, data1.edge_index).detach()\n",
    "\t\t\tz2 = model(data2.x, data2.edge_index).detach()\n",
    "\t\t\t\n",
    "\t\t\t# Similarity matrix\n",
    "\t\t\t# option 1\n",
    "\t\t\tD = torch.cdist(z1, z2, 2)\n",
    "\n",
    "\t\t\t# option 2 (GPU problem)\n",
    "\t\t\t# D = 1 - F.cosine_similarity(z1.unsqueeze(1), z2.unsqueeze(0), dim=-1)\n",
    "\n",
    "\t\t\t# option 3 (Decoder cosine similarity)\n",
    "\t\t\t\" \"\" z1n = F.normalize(z1, dim=1)\n",
    "\t\t\tz2n = F.normalize(z2, dim=1)\n",
    "\t\t\tD = 1 - (z1n @ z2n.T) \" \"\"\n",
    "\n",
    "\t\t\tif dataset == \"ACM_DBLP\":\n",
    "\t\t\t\ttest_idx = test_pairs[:, 0].astype(int)\n",
    "\t\t\t\tlabels = test_pairs[:, 1].astype(int)\n",
    "\t\t\telse:\n",
    "\t\t\t\ttest_idx = test_pairs[0, :].astype(int)\n",
    "\t\t\t\tlabels = test_pairs[1, :].astype(int)\n",
    "\t\t\t\t\n",
    "\t\t\thitAtOne = 0\n",
    "\t\t\thitAtFive = 0\n",
    "\t\t\thitAtTen = 0\n",
    "\t\t\thitAtFifty = 0\n",
    "\t\t\thitAtHundred = 0\n",
    "\t\t\tfor i in range(len(test_idx)):\n",
    "\t\t\t\tdist_list = D[test_idx[i]]\n",
    "\t\t\t\tsorted_neighbors = torch.argsort(dist_list).cpu()\n",
    "\t\t\t\tlabel = labels[i]\n",
    "\t\t\t\tfor j in range(100):\n",
    "\t\t\t\t\tif (sorted_neighbors[j].item() == label):\n",
    "\t\t\t\t\t\tif (j == 0):\n",
    "\t\t\t\t\t\t\thitAtOne += 1\n",
    "\t\t\t\t\t\t\thitAtFive += 1\n",
    "\t\t\t\t\t\t\thitAtTen += 1\n",
    "\t\t\t\t\t\t\thitAtFifty += 1\n",
    "\t\t\t\t\t\t\thitAtHundred += 1\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\telif (j <= 4):\n",
    "\t\t\t\t\t\t\thitAtFive += 1\n",
    "\t\t\t\t\t\t\thitAtTen += 1\n",
    "\t\t\t\t\t\t\thitAtFifty += 1\n",
    "\t\t\t\t\t\t\thitAtHundred += 1\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\telif (j <= 9):\n",
    "\t\t\t\t\t\t\thitAtTen += 1\n",
    "\t\t\t\t\t\t\thitAtFifty += 1\n",
    "\t\t\t\t\t\t\thitAtHundred += 1\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\telif (j <= 49):\n",
    "\t\t\t\t\t\t\thitAtFifty += 1\n",
    "\t\t\t\t\t\t\thitAtHundred += 1\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\telif (j <= 100):\n",
    "\t\t\t\t\t\t\thitAtHundred += 1\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\tcur_hitAtOne = hitAtOne / len(test_idx)\n",
    "\t\t\tcur_hitAtFive = hitAtFive / len(test_idx)\n",
    "\t\t\tcur_hitAtTen = hitAtTen / len(test_idx)\n",
    "\t\t\tcur_hitAtFifty = hitAtFifty / len(test_idx)\n",
    "\n",
    "\t\t\tif(cur_hitAtOne > best_hitAtOne): best_hitAtOne = cur_hitAtOne\n",
    "\t\t\tif (cur_hitAtFive > best_hitAtFive): best_hitAtFive = cur_hitAtFive\n",
    "\t\t\tif (cur_hitAtTen > best_hitAtTen): best_hitAtTen = cur_hitAtTen\n",
    "\t\t\tif (cur_hitAtFifty > best_hitAtFifty): best_hitAtFifty = cur_hitAtFifty\n",
    "\n",
    "\tprint(\"The best results achieved:\")\n",
    "\tprint(\"Hit@1: \", end=\"\")\n",
    "\tprint(best_hitAtOne)\n",
    "\tprint(\"Hit@5: \", end=\"\")\n",
    "\tprint(best_hitAtFive)\n",
    "\tprint(\"Hit@10: \", end=\"\")\n",
    "\tprint(best_hitAtTen)\n",
    "\tprint(\"Hit@50: \", end=\"\")\n",
    "\tprint(best_hitAtFifty) \"\"\"\n",
    "\n",
    "\t# Evaluation (for others dataset)\n",
    "\tdict_node_embeddings = {}\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\tfor ts in train_set:\n",
    "\t\t\tdata = train_loader[ts]\n",
    "\t\t\tif encoder == \"GIN\":\n",
    "\t\t\t\tz = model(data.x, data.edge_index).detach()\n",
    "\t\t\telif encoder == \"GINE\":\n",
    "\t\t\t\tz = model(data.x, data.edge_index, data.edge_weight).detach()\n",
    "\t\t\tdict_node_embeddings[ts] = z.cpu().numpy()\n",
    "\n",
    "\ttorch.cuda.empty_cache()\n",
    "\n",
    "\treturn dict_node_embeddings, list_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42d302dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Red_1', 'Red_2']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a20de1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training features\n",
      "Fitting model\n",
      "mentos_05 0.0001 100 6 16 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1:   0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "NVML_SUCCESS == DriverAPI::get()->nvmlInit_v2_() INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":983, please report a bug to PyTorch. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset, lr, epochs, input_dim, output_feature_size, no_samples)\n\u001b[0;32m---> 19\u001b[0m dict_node_embeddings, list_loss \u001b[38;5;241m=\u001b[39m \u001b[43mfit_TGAE_subgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pairs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 32\u001b[0m, in \u001b[0;36mfit_TGAE_subgraph\u001b[0;34m(encoder, dataset, no_samples, model, epochs, train_loader, lr, test_pairs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \t\u001b[38;5;66;03m# z = F.normalize(z, dim=1)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m encoder \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGINE\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m \tz \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Positive edges\u001b[39;00m\n\u001b[1;32m     35\u001b[0m pos_edge_index \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39medge_index\n",
      "File \u001b[0;32m~/miniconda3/envs/graph_matching/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/graph_matching/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Project/T-GAE_PyG/model_PyG.py:95\u001b[0m, in \u001b[0;36mTGAE_GINE.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, edge_attr):\n\u001b[0;32m---> 95\u001b[0m \tz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m z\n",
      "File \u001b[0;32m~/miniconda3/envs/graph_matching/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/graph_matching/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Project/T-GAE_PyG/model_PyG.py:81\u001b[0m, in \u001b[0;36mTGAE_Encoder_GINE.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs:\n\u001b[1;32m     80\u001b[0m \tx_cat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([initial_x, x], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 81\u001b[0m \tx \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \thidden_states\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m     84\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(hidden_states, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/graph_matching/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/graph_matching/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/graph_matching/lib/python3.10/site-packages/torch_geometric/nn/conv/gin_conv.py:187\u001b[0m, in \u001b[0;36mGINEConv.forward\u001b[0;34m(self, x, edge_index, edge_attr, size)\u001b[0m\n\u001b[1;32m    184\u001b[0m     x \u001b[38;5;241m=\u001b[39m (x, x)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/tmp/torch_geometric.nn.conv.gin_conv_GINEConv_propagate_rwoch1iq.py:183\u001b[0m, in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, edge_attr, size)\u001b[0m\n\u001b[1;32m    174\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m CollectArgs(\n\u001b[1;32m    175\u001b[0m                 x_j\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_j\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    176\u001b[0m                 edge_attr\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_attr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mdim_size,\n\u001b[1;32m    180\u001b[0m             )\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# End Message Forward Pre Hook #########################################\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_j\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_j\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Begin Message Forward Hook ###########################################\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[0;32m~/miniconda3/envs/graph_matching/lib/python3.10/site-packages/torch_geometric/nn/conv/gin_conv.py:204\u001b[0m, in \u001b[0;36mGINEConv.message\u001b[0;34m(self, x_j, edge_attr)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     edge_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(edge_attr)\n\u001b[0;32m--> 204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mx_j\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NVML_SUCCESS == DriverAPI::get()->nvmlInit_v2_() INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":983, please report a bug to PyTorch. "
     ]
    }
   ],
   "source": [
    "no_samples = len(train_set) # * (1 + 1)  # num datasets * num of samples by dataset \n",
    "input_dim = train_loader[train_set[0]].num_node_features\n",
    "\n",
    "if encoder == \"GIN\":\n",
    "\tmodel = TGAE_GIN(NUM_HIDDEN_LAYERS,\n",
    "\t\t\t\tinput_dim,\n",
    "\t\t\t\tHIDDEN_DIM,\n",
    "\t\t\t\toutput_feature_size).to(device)\n",
    "elif encoder == \"GINE\":\n",
    "\tmodel = TGAE_GINE(NUM_HIDDEN_LAYERS,\n",
    "\t\t\t\tinput_dim,\n",
    "\t\t\t\tHIDDEN_DIM,\n",
    "\t\t\t\toutput_feature_size).to(device)\n",
    "\n",
    "print(\"Generating training features\")\n",
    "print(\"Fitting model\")\n",
    "print(dataset, lr, epochs, input_dim, output_feature_size, no_samples)\n",
    "\n",
    "dict_node_embeddings, list_loss = fit_TGAE_subgraph(encoder, dataset, no_samples, model, epochs, train_loader, lr, test_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68144961",
   "metadata": {},
   "source": [
    "### Get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a1d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_node_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e3b5a9",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153da7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate embeddings\n",
    "\n",
    "node_embeddings_cat = np.concatenate(list(dict_node_embeddings.values()), axis=0)\n",
    "print(node_embeddings_cat.shape)\n",
    "node_embeddings_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447e4b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels\n",
    "\n",
    "labels = []\n",
    "for i, node_embeddings in enumerate(list(dict_node_embeddings.values())):\n",
    "    labels += [i] * node_embeddings.shape[0]\n",
    "print(len(labels))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee712f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162839da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(list_loss) + 1), list_loss) #, marker=\".\")\n",
    "# plt.plot(range(1, len(list_loss) + 1), np.log(list_loss)) #, marker=\".\")\n",
    "plt.title(\"Training Loss over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5de7329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node embeddings 3D\n",
    "\n",
    "if node_embeddings_cat.shape[1] > 3:\n",
    "\tpca = PCA(n_components=3)\n",
    "\tnode_embeddings_cat_3d = pca.fit_transform(node_embeddings_cat)\n",
    "else:\n",
    "\tnode_embeddings_cat_3d = node_embeddings_cat.copy()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "for c in np.unique(labels):\n",
    "\tax.scatter(\n",
    "\t\tnode_embeddings_cat_3d[:, 0][labels == c],\n",
    "\t\tnode_embeddings_cat_3d[:, 1][labels == c], \n",
    "\t\tnode_embeddings_cat_3d[:, 2][labels == c],\n",
    "\t\ts=10,\n",
    "\t\talpha=0.5,\n",
    "\t\tlabel=f\"{train_set[c]}\"\n",
    "\t)\n",
    "\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0767f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node embeddings 2D\n",
    "\n",
    "if node_embeddings_cat.shape[1] > 2:\n",
    "\tpca = PCA(n_components=2)\n",
    "\tnode_embeddings_cat_2d = pca.fit_transform(node_embeddings_cat)\n",
    "else:\n",
    "\tnode_embeddings_cat_2d = node_embeddings_cat.copy()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for c in np.unique(labels):\n",
    "\tidx = labels == c\n",
    "\tax.scatter(\n",
    "\t\tnode_embeddings_cat_2d[idx, 0],\n",
    "\t\tnode_embeddings_cat_2d[idx, 1],\n",
    "\t\ts=10,\n",
    "\t\talpha=0.5,\n",
    "\t\tlabel=f\"{train_set[c]}\"\n",
    "\t)\n",
    "\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8028f8",
   "metadata": {},
   "source": [
    "### Similarity analysis (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6bc8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8f1213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get node ids\n",
    "\n",
    "dict_node_id = {}\n",
    "\n",
    "if dataset in [\"vanessa_05\", \"mentos_05\"]:\n",
    "\tfor ts in train_set:\n",
    "\t\tdf_nodes = pd.read_csv(\"data/{}/nodes_{}.csv\".format(dataset, ts))\n",
    "\t\t# idx,id,mz,rt,intensity_mean,intensity_cv\n",
    "\n",
    "\t\tdict_node_id[ts] = df_nodes[\"id\"].values\n",
    "else:\n",
    "    for ts in train_set:\n",
    "        dict_node_id[ts] = np.arange(len(dict_node_embeddings[ts]))\n",
    "dict_node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a10a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance matrix (KNN)\n",
    "\n",
    "k = 1 # Change\n",
    "knn = NearestNeighbors(n_neighbors=k, metric=\"euclidean\")\n",
    "\n",
    "first_ts = train_set[0]\n",
    "x = dict_node_embeddings[first_ts]\n",
    "\n",
    "df_node_alignment = pd.DataFrame()\n",
    "df_node_alignment[first_ts] = dict_node_id[first_ts]\n",
    "\n",
    "for ts in train_set[1:]:\n",
    "\ty = dict_node_embeddings[ts]\n",
    "\t\n",
    "\tknn.fit(y)\n",
    "\tdistances, indices = knn.kneighbors(x)\n",
    "\t\n",
    "\tdf_node_alignment[ts] = dict_node_id[ts][indices]\n",
    "df_node_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find node alignment 2 by 2\n",
    "\n",
    "col1, col2 = train_set[:2] # Change\n",
    "print(col1, col2)\n",
    "\n",
    "df_node_alignment_filter = df_node_alignment[df_node_alignment.apply(lambda row: row[col1] == row[col2], axis=1)]\n",
    "df_node_alignment_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27212958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find node alignment for all datasets\n",
    "\n",
    "df_node_alignment_filter = df_node_alignment[df_node_alignment.nunique(axis=1) == 1]\n",
    "print(len(df_node_alignment_filter))\n",
    "df_node_alignment_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8bdf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison (with test_pairs)\n",
    "\n",
    "if dataset not in [\"vanessa_05\", \"mentos_05\"]:\n",
    "\tprint(len(test_pairs))\n",
    "\t# print(test_pairs)\n",
    "\t# print(df_node_alignment.values)\n",
    "\tmask = np.array([tuple(row) in map(tuple, test_pairs) for row in df_node_alignment.values])\n",
    "\tdf_node_alignment[\"mask\"] = mask\n",
    "\tprint(df_node_alignment[df_node_alignment[\"mask\"] == True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb544559",
   "metadata": {},
   "source": [
    "### Filter MS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76d26c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_node_id = df_node_alignment_filter.iloc[:, 1].values\n",
    "common_node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba94959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data\n",
    "\n",
    "df_join_raw = pd.read_csv(\"data/{}/raw.csv\".format(dataset), index_col=0)\n",
    "df_join_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4839cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(common_node_id), len(df_join_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf8b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_raw_filter = df_join_raw.loc[common_node_id].iloc[:, [0, 1, 2]]\n",
    "df_join_raw_filter.to_csv(f\"data/{dataset}/output/node_alignment.csv\", sep=\";\", decimal=\",\", index_label=\"Id\")\n",
    "df_join_raw_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc92525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison (sta vs Van)\n",
    "\n",
    "list_node_id_sta = [39, 52, 70, 79, 94, 91, 90, 116, 123, 126, 127, 159, 157, 160, 175, 188, 190, 189, 173, 205, 202, 211, 212]\n",
    "\n",
    "match = set(list_node_id_sta) & set(common_node_id)\n",
    "print(train_set)\n",
    "print(f\"Alignment: {len(common_node_id)} / {len(df_join_raw)}\")\n",
    "print(f\"Match comp: {len(match)}/{len(list_node_id_sta)}\")\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c298692",
   "metadata": {},
   "source": [
    "### Clustering analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33abb568",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b171b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_raw_signal = df_join_raw.loc[common_node_id].iloc[:, 3:-2] # Important two last column no only to Mentos\n",
    "df_join_raw_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd5987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_raw_signal_t = df_join_raw_signal.T\n",
    "df_join_raw_signal_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f67780",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_join_raw_signal_t.values)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b305d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1193999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [item.split(\"_\")[0] for item in df_join_raw_signal_t.index]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0ad8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = X_pca[:, 0], X_pca[:, 1]\n",
    "\n",
    "unique_groups = [\"Red\", \"Yellow\", \"Orange\"] # np.unique(labels)\n",
    "\n",
    "for group in unique_groups:\n",
    "    xi = [x[i] for i in range(len(x)) if labels[i] == group]\n",
    "    yi = [y[i] for i in range(len(y)) if labels[i] == group]\n",
    "    plt.scatter(xi, yi, label=group)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"C1\")\n",
    "plt.ylabel(\"C2\")\n",
    "plt.title(f\"Clustering {train_set}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c262e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_tsne = TSNE(n_components=2, learning_rate=\"auto\", init=\"pca\", perplexity=3).fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fa838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = X_tsne[:, 0], X_tsne[:, 1]\n",
    "\n",
    "unique_groups = [\"Red\", \"Yellow\", \"Orange\"] # np.unique(labels)\n",
    "\n",
    "for group in unique_groups:\n",
    "    xi = [x[i] for i in range(len(x)) if labels[i] == group]\n",
    "    yi = [y[i] for i in range(len(y)) if labels[i] == group]\n",
    "    plt.scatter(xi, yi, label=group)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"C1\")\n",
    "plt.ylabel(\"C2\")\n",
    "plt.title(f\"Clustering {train_set}\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_matching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
